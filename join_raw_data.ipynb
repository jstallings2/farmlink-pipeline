{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"loops over raw data downloaded by scrape_usda.ipynb and just concatenates \\neach produce item's data across all years by city\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "\"\"\"loops over raw data downloaded by scrape_usda.ipynb and just concatenates \n",
    "each produce item's data across all years by city\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "@Farmlink: This could be extended to put everything into one giant dataframe, that has all the regions and all the veggies, pretty easily. Right now each combo of veggie and region gets its own csv (will change to group by type of veggie as well)\n",
    "### TODO: ###\n",
    "- Extend this notebook or make a new one to calculate averages and upload to MongoDB."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "raw_dir = './raw_data/'\n",
    "save_dir = './concat_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat function\n",
    "def concat_add(input_array, veg, reg, yr):\n",
    "    new_data = pd.read_html(raw_dir+str(veg)+'_'+str(reg)+'_'+str(yr)+'.html', header=0, parse_dates=True)[0]\n",
    "    output_data = pd.concat([input_array, new_data], ignore_index=True)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just loop over the downloaded files and combine same veggies from one city across all years\n",
    "#cities = ['NEW+YORK', 'LOS+ANGELES']\n",
    "regions = ['NORTHEAST+U.S.', 'SOUTHWEST+U.S.']\n",
    "veggies = ['APPLES','CARROTS']\n",
    "# veggies = ['APPLES','APRICOTS','ASPARAGUS','AVOCADOS','BANANAS','BEANS','BEETS','BLACKBERRIES','BLUEBERRIES','BROCCOLI','BRUSSELS+SPROUTS','CABBAGE','CANTALOUPS','CARROTS','CAULIFLOWER','CELERY','CHERRIES','CLEMENTINES','CORN-SWEET','CRANBERRIES', 'CUCUMBERS','EGGPLANT','ENDIVE','GARLIC','GINGER+ROOT','GRAPEFRUIT','GRAPES','HONEYDEWS','KIWIFRUIT','LEMONS','LETTUCE%2C+ICEBERG','LETTUCE%2C+ROMAINE','LETTUCE%2C+RED+LEAF','LETTUCE%2C+GREEN+LEAF', 'LIMES','MANGOES','MUSHROOMS','NECTARINES','OKRA','ORANGES','PEACHES','PEARS','PEAS+GREEN','PEPPERS%2C+BELL+TYPE','PINEAPPLES','PLUMS','POTATOES','PUMPKINS','RADISHES','RASPBERRIES','RHUBARB','SPINACH','SQUASH','STRAWBERRIES','SWEET+POTATOES','TOMATOES','TURNIPS','WATERMELONS']\n",
    "years = ['2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018','2019','2020','2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "joined NORTHEAST+U.S. APPLES\n",
      "joined NORTHEAST+U.S. CARROTS\n",
      "joined SOUTHWEST+U.S. APPLES\n",
      "joined SOUTHWEST+U.S. CARROTS\n"
     ]
    }
   ],
   "source": [
    "# loop\n",
    "for r in regions:\n",
    "    for v in veggies:\n",
    "        if str(r)+'_'+str(v)+'_ALL.csv' not in os.listdir(save_dir):\n",
    "            for y in years:\n",
    "                data_exists = True\n",
    "                if y == years[0]:\n",
    "                    try:\n",
    "                        first_data = pd.read_html(raw_dir+str(v)+'_'+str(r)+'_'+str(y)+'.html', header=0)[0]\n",
    "                    except IndexError:\n",
    "                        print('no data for '+v+', skipping...')\n",
    "                        data_exists = False\n",
    "                        break\n",
    "                else:\n",
    "                    first_data = concat_add(first_data, v, r, y)\n",
    "            if data_exists:\n",
    "                first_data.to_csv(save_dir+str(r)+'_'+str(v)+'_ALL.csv')\n",
    "                print('joined '+r + ' ' +v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}