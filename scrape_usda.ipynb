{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"This notebook scrapes the USDA market research website for historical wholesale produce data\\nThis is done by linking directly to a server request output in html form\\nOnly one year of data can be requested at a time so this notebook loops over years.\\n\\nTo use this in the future don't forget to: look up the short city code for each city, as well as short produce name.\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "\"\"\"This notebook scrapes the USDA market research website for historical wholesale produce data\n",
    "This is done by linking directly to a server request output in html form\n",
    "Only one year of data can be requested at a time so this notebook loops over years.\n",
    "\n",
    "To use this in the future don't forget to: look up the short city code for each city, as well as short produce name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "### TODO: ###\n",
    "- Edit `fetch_data()` to fetch the latest week of data by changing the parameter repDate= to the current date in the URL (will need to use datetime and `.now()` to get the current date)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(producename, regionname, year, directory):\n",
    "    \"\"\"Given a region and produce item, fetches a year of data and saves it in a target directory.\n",
    "    Skips any cities/items/year combos that have already been downloaded. Slightly hardened against \n",
    "    timeouts,etc. from the USDA server, which is a bit flaky.\n",
    "    \"\"\"\n",
    "    if str(producename)+'_'+str(regionname)+'_'+str(year)+'.html' not in os.listdir(directory):\n",
    "\n",
    "        url = 'https://www.marketnews.usda.gov/mnp/fv-report-retail?repType=&run=&portal=fv&locChoose=&commodityClass=&startIndex=1&type=retail&class=ALL&commodity='+str(producename)+'&region='+str(regionname)+'&organic=ALL&repDate=01%2F01%2F'+str(year)+'&endDate=12%2F31%2F'+str(year)+'&compareLy=No&format=excel&rowDisplayMax=100000'\n",
    "\n",
    "        try:\n",
    "            r = requests.get(url, allow_redirects=True, timeout=300)\n",
    "            open(str(directory) + str(producename)+'_'+str(regionname)+'_'+str(year)+'.html', 'wb').write(r.content)\n",
    "            return True\n",
    "        except requests.exceptions.Timeout:\n",
    "            print('request timed out, trying again...')\n",
    "            try:\n",
    "                r = requests.get(url, allow_redirects=True, timeout=300)\n",
    "                open(str(directory) + str(producename)+'_'+str(regionname)+'_'+str(year)+'.html', 'wb').write(r.content)\n",
    "                return True\n",
    "            except requests.exceptions.Timeout:\n",
    "                print('request timed out again, exiting...')\n",
    "                sys.exit()\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test grabbing a single item for 1/1/21 to 1/22/21\n",
    "# test_city = 'NEW+YORK'\n",
    "test_regions = ['NORTHEAST+U.S.', 'SOUTHWEST+U.S.']\n",
    "#test_short = 'NX'\n",
    "test_producenames = ['CARROTS', 'APPLES']\n",
    "test_year = ['2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_data(test_city, test_producename, test_year)\n",
    "#veggies = ['APPLES','APRICOTS','ASPARAGUS','AVOCADOS','BANANAS','BEANS','BEETS','BLACKBERRIES','BLUEBERRIES','BROCCOLI','BRUSSELS+SPROUTS','CABBAGE','CANTALOUPS','CARROTS','CAULIFLOWER','CELERY','CHERRIES','CLEMENTINES','CORN-SWEET','CRANBERRIES', 'CUCUMBERS','EGGPLANT','ENDIVE','GARLIC','GINGER+ROOT','GRAPEFRUIT','GRAPES','HONEYDEWS','KALE+GREENS','KIWIFRUIT','KOHLRABI','LEMONS','LETTUCE%2C+ICEBERG','LETTUCE%2C+ROMAINE','LETTUCE%2C+RED+LEAF','LETTUCE%2C+GREEN+LEAF','LETTUCE%2C+BIBB']\n",
    "#shortveg = ['APL','APR','ASP','AVOC','BAN','BNS','BTS','BLKBERI-V','BLUBY','BROC','BRSPT','CAB','CANT','CARR','CAUL','CEL','CHER','CLEM','CORN','CRBY','CUX','EGPLT','END','GARLIC','GNGRT','GRPFT','GRPS','HDEW','KALEGRNS','KIWI','KOHLRABI','LEM','LETT','LETTR','RDLFLET-V','GRNLFLET-V','BIBBLET-V']"
   ]
  },
  {
   "source": [
    "### Scrape parameters ###\n",
    "In the next cell, you can add the veggies, regions, and years you want to scrape for.\n",
    "In the updated version of the scrape, only veggies, regions, and years matter.\n",
    "The scrape is hard-coded to scrape a whole year (1/1 to 12/31) except for the current year 2021. (There will be another version that just gets 2021 up to present)\n",
    "This version scrapes all the data that we will need as of 1/22/21 back 10 years, to calculate all the averages. That should only be run once and manually dumped into Mongo; in the future a version of this will be set to scrape for the most recently updated week every Friday and run it through the pipeline (calculate new rolling averages, etc.) and dump into Mongo, all on the cloud using the cloud function.\n",
    "\n",
    "All veggies are included since they want to know which specific veggies to go after."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over a few veggies/years/cities and dump into directory\n",
    "veggies = ['APPLES','APRICOTS','ASPARAGUS','AVOCADOS','BANANAS','BEANS','BEETS','BLACKBERRIES','BLUEBERRIES','BROCCOLI','BRUSSELS+SPROUTS','CABBAGE','CANTALOUPS','CARROTS','CAULIFLOWER','CELERY','CHERRIES','CLEMENTINES','CORN-SWEET','CRANBERRIES', 'CUCUMBERS','EGGPLANT','ENDIVE','GARLIC','GINGER+ROOT','GRAPEFRUIT','GRAPES','HONEYDEWS','KALE+GREENS','KIWIFRUIT','KOHLRABI','LEMONS','LETTUCE%2C+ICEBERG','LETTUCE%2C+ROMAINE','LETTUCE%2C+RED+LEAF','LETTUCE%2C+GREEN+LEAF','LETTUCE%2C+BIBB', 'LIMES','MANGOES','MUSHROOMS','NECTARINES','OKRA','ORANGES','PEACHES','PEARS','PEAS+GREEN','PEPPERS%2C+BELL+TYPE','PINEAPPLES','PLUMS','POTATOES','PUMPKINS','RADISHES','RASPBERRIES','RHUBARB','SPINACH','SQUASH','STRAWBERRIES','SWEET+POTATOES','TOMATOES','TURNIPS','WATERMELONS']\n",
    "# shortveg = ['APL','APR','ASP','AVOC','BAN','BNS','BTS','BLKBERI-V','BLUBY','BROC','BRSPT','CAB','CANT','CARR','CAUL','CEL','CHER','CLEM','CORN','CRBY','CUX','EGPLT','END','GARLIC','GNGRT','GRPFT','GRPS','HDEW','KALEGRNS','KIWI','KOHLRABI','LEM','LETT','LETTR','RDLFLET-V','GRNLFLET-V','BIBBLET-V','LIM','MANGO','MUSH','NECT','OKRA','ORG','PCH','PEAR','PEASG','PEP','PINE','PLUM','POTS','PUMP','RAD','RASP','RHUB','SPIN','SQU','STRBY','SWPOT','TOM','TRNP','WMEL']\n",
    "regions = ['NORTHEAST+U.S.', 'SOUTHEAST+U.S.', 'MIDWEST+U.S.', 'SOUTH+CENTRAL+U.S.', 'SOUTHWEST+U.S.', 'NORTHWEST+U.S.', 'HAWAII', 'ALASKA']\n",
    "#shortveg = ['APL','APR','ASP','AVOC','BAN','BNS','BTS','BLKBERI-V','BLUBY','BROC']\n",
    "years = ['2011','2012','2013','2014','2015','2016','2017','2018','2019', '2020']\n",
    "\n",
    "targdir = './raw_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fetched NORTHEAST+U.S. APPLES 2021, sleeping for 17s\n",
      "fetched in 18.06s\n"
     ]
    }
   ],
   "source": [
    "# loop over all the produce items, cities specified above. this can take a while. \n",
    "initial_time = time.time()\n",
    "count_region = 0\n",
    "for reg in test_regions:\n",
    "    count_veg = 0\n",
    "    for v in test_producenames:\n",
    "        for y in test_year:\n",
    "            random.seed()\n",
    "            sleeptime = random.randint(8, 18)\n",
    "            try:\n",
    "                if fetch_data(v, reg, y, targdir):\n",
    "                    print('fetched '+str(reg)+' '+str(v)+' '+str(y)+', sleeping for '+str(sleeptime)+'s')\n",
    "                    time.sleep(sleeptime)\n",
    "            except OSError:\n",
    "                print('problem fetching, trying again...')\n",
    "                try:\n",
    "                    if fetch_data(v, reg, y, targdir):\n",
    "                        print('fetched '+str(reg)+' '+str(v)+' '+str(y)+', sleeping for '+str(sleeptime)+'s')\n",
    "                        time.sleep(sleeptime)\n",
    "                except OSError:\n",
    "                    print('problem fetching, trying one last time...')\n",
    "                    if fetch_data(v, reg, y, targdir):\n",
    "                        print('fetched '+str(reg)+' '+str(v)+' '+str(y)+', sleeping for '+str(sleeptime)+'s')\n",
    "                        time.sleep(sleeptime)        \n",
    "        count_veg+=1\n",
    "    count_region+=1\n",
    "final_time = time.time()\n",
    "print('fetched in '+str(round(final_time-initial_time, 2))+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}